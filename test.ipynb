{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.default import Opts\n",
    "from models.networks import load_checkpoint_parallel\n",
    "from models.afwm import AFWM_Vitonhd_lrarms, AFWM_Dressescode_lrarms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "opt = Opts()\n",
    "os.makedirs('sample/'+opt.name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataset(opt):\n",
    "    if opt.dataset == 'vitonhd':\n",
    "        from data.aligned_dataset_vitonhd import AlignedDataset\n",
    "        dataset = AlignedDataset()\n",
    "        dataset.initialize(opt, mode='test')\n",
    "    elif opt.dataset == 'dresscode':\n",
    "        from data.aligned_dataset_dresscode import AlignedDataset\n",
    "        dataset = AlignedDataset()\n",
    "        dataset.initialize(opt, mode='test', stage='warp')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "device = torch.device(f'cuda:{0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = CreateDataset(opt)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=opt.batchSize, shuffle=False,\n",
    "                          num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_model = AFWM_Vitonhd_lrarms(opt, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AFWM_Vitonhd_lrarms(\n",
       "  (image_features): FeatureEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cond_features): FeatureEncoder(\n",
       "    (encoders): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(51, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(51, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3-4): 2 x Sequential(\n",
       "        (0): DownSample(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (image_FPN): RefinePyramid(\n",
       "    (adaptive): ModuleList(\n",
       "      (0-2): 3 x Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (smooth): ModuleList(\n",
       "      (0-4): 5 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (cond_FPN): RefinePyramid(\n",
       "    (adaptive): ModuleList(\n",
       "      (0-2): 3 x Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (smooth): ModuleList(\n",
       "      (0-4): 5 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (aflow_net): AFlowNet_Vitonhd_lrarms(\n",
       "    (netLeftMain): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netTorsoMain): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netRightMain): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(49, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netLeftRefine): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netTorsoRefine): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netRightRefine): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (netAttentionRefine): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (netPartFusion): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "            (4): ReLU(inplace=True)\n",
       "            (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (netSeg): ModuleList(\n",
       "      (0-4): 5 x Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.1)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.1)\n",
       "        (6): Conv2d(32, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp_model.train()\n",
    "warp_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint_parallel(warp_model, opt.PBAFN_warp_checkpoint)\n",
    "\n",
    "warp_model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(warp_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if opt.isTrain and len(opt.gpu_ids):\n",
    "#     model = torch.nn.parallel.DistributedDataParallel(\n",
    "#         warp_model, device_ids=[0])\n",
    "model = warp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/workspace/viton/data/aligned_dataset_vitonhd.py\", line 174, in __getitem__\n    with open(pose_path, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/workspace/viton/person_keypoints.json'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/viton/test.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B213.173.102.215/workspace/viton/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m ii, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm\u001b[39m.\u001b[39mtqdm(train_loader)):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B213.173.102.215/workspace/viton/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B213.173.102.215/workspace/viton/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         pre_clothes_edge \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39medge\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/workspace/viton/data/aligned_dataset_vitonhd.py\", line 174, in __getitem__\n    with open(pose_path, 'r') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/workspace/viton/person_keypoints.json'\n"
     ]
    }
   ],
   "source": [
    "for ii, data in enumerate(tqdm.tqdm(train_loader)):\n",
    "    with torch.no_grad():\n",
    "        pre_clothes_edge = data['edge']\n",
    "        clothes = data['color']\n",
    "        clothes = clothes * pre_clothes_edge\n",
    "        pose = data['pose']\n",
    "\n",
    "        size = data['color'].size()\n",
    "        oneHot_size1 = (size[0], 25, size[2], size[3])\n",
    "        densepose = torch.cuda.FloatTensor(torch.Size(oneHot_size1)).zero_()\n",
    "        densepose = densepose.scatter_(1,data['densepose'].data.long().cuda(),1.0)\n",
    "        densepose = densepose * 2.0 - 1.0\n",
    "        densepose_fore = data['densepose']/24.0\n",
    "\n",
    "        left_cloth_sleeve_mask = data['flat_clothes_left_mask']\n",
    "        cloth_torso_mask = data['flat_clothes_middle_mask']\n",
    "        right_cloth_sleeve_mask = data['flat_clothes_right_mask']\n",
    "\n",
    "        clothes_left = clothes * left_cloth_sleeve_mask\n",
    "        clothes_torso = clothes * cloth_torso_mask\n",
    "        clothes_right = clothes * right_cloth_sleeve_mask\n",
    "\n",
    "        cloth_parse_for_d = data['flat_clothes_label'].cuda()\n",
    "        pose = pose.cuda()\n",
    "        clothes = clothes.cuda()\n",
    "        clothes_left = clothes_left.cuda()\n",
    "        clothes_torso = clothes_torso.cuda()\n",
    "        clothes_right = clothes_right.cuda()\n",
    "        pre_clothes_edge = pre_clothes_edge.cuda()\n",
    "        left_cloth_sleeve_mask = left_cloth_sleeve_mask.cuda()\n",
    "        cloth_torso_mask = cloth_torso_mask.cuda()\n",
    "        right_cloth_sleeve_mask = right_cloth_sleeve_mask.cuda()\n",
    "        preserve_mask3 = data['preserve_mask3'].cuda()\n",
    "\n",
    "        if opt.resolution == 512:\n",
    "            concat = torch.cat([densepose, pose, preserve_mask3], 1)\n",
    "            if opt.dataset == 'vitonhd':\n",
    "                flow_out = model(concat, clothes, pre_clothes_edge, cloth_parse_for_d, \\\n",
    "                                clothes_left, clothes_torso, clothes_right, \\\n",
    "                                left_cloth_sleeve_mask, cloth_torso_mask, right_cloth_sleeve_mask, \\\n",
    "                                preserve_mask3)\n",
    "            elif opt.dataset == 'dresscode':\n",
    "                cloth_type = data['flat_clothes_type'].cuda()\n",
    "                flow_out = model(concat, clothes, pre_clothes_edge, cloth_parse_for_d, \\\n",
    "                                clothes_left, clothes_torso, clothes_right, \\\n",
    "                                left_cloth_sleeve_mask, cloth_torso_mask, right_cloth_sleeve_mask, \\\n",
    "                                preserve_mask3, cloth_type)\n",
    "\n",
    "            last_flow, last_flow_all, delta_list, x_all, x_edge_all, delta_x_all, delta_y_all, \\\n",
    "                x_full_all, x_edge_full_all, attention_all, seg_list = flow_out\n",
    "        else:\n",
    "            densepose_ds = F.interpolate(densepose, scale_factor=0.5, mode='nearest')\n",
    "            pose_ds = F.interpolate(pose, scale_factor=0.5, mode='nearest')\n",
    "            preserve_mask3_ds = F.interpolate(preserve_mask3, scale_factor=0.5, mode='nearest')\n",
    "            concat = torch.cat([densepose_ds, pose_ds, preserve_mask3_ds], 1)\n",
    "\n",
    "            clothes_ds = F.interpolate(clothes, scale_factor=0.5, mode='bilinear')\n",
    "            pre_clothes_edge_ds = F.interpolate(pre_clothes_edge, scale_factor=0.5, mode='nearest')\n",
    "            cloth_parse_for_d_ds = F.interpolate(cloth_parse_for_d, scale_factor=0.5, mode='nearest')\n",
    "            clothes_left_ds = F.interpolate(clothes_left, scale_factor=0.5, mode='bilinear')\n",
    "            clothes_torso_ds = F.interpolate(clothes_torso, scale_factor=0.5, mode='bilinear')\n",
    "            clothes_right_ds = F.interpolate(clothes_right, scale_factor=0.5, mode='bilinear')\n",
    "            left_cloth_sleeve_mask_ds = F.interpolate(left_cloth_sleeve_mask, scale_factor=0.5, mode='nearest')\n",
    "            cloth_torso_mask_ds = F.interpolate(cloth_torso_mask, scale_factor=0.5, mode='nearest')\n",
    "            right_cloth_sleeve_mask_ds = F.interpolate(right_cloth_sleeve_mask, scale_factor=0.5, mode='nearest')\n",
    "\n",
    "            if opt.dataset == 'vitonhd':\n",
    "                flow_out = model(concat, clothes_ds, pre_clothes_edge_ds, cloth_parse_for_d_ds, \\\n",
    "                                clothes_left_ds, clothes_torso_ds, clothes_right_ds, \\\n",
    "                                left_cloth_sleeve_mask_ds, cloth_torso_mask_ds, right_cloth_sleeve_mask_ds, \\\n",
    "                                preserve_mask3_ds)\n",
    "            elif opt.dataset == 'dresscode':\n",
    "                cloth_type = data['flat_clothes_type'].cuda()\n",
    "                cloth_type_ds = F.interpolate(cloth_type, scale_factor=0.5, mode='bilinear')\n",
    "                flow_out = model(concat, clothes_ds, pre_clothes_edge_ds, cloth_parse_for_d_ds, \\\n",
    "                                clothes_left_ds, clothes_torso_ds, clothes_right_ds, \\\n",
    "                                left_cloth_sleeve_mask_ds, cloth_torso_mask_ds, right_cloth_sleeve_mask_ds, \\\n",
    "                                preserve_mask3_ds, cloth_type_ds)\n",
    "                \n",
    "            last_flow, last_flow_all, delta_list, x_all, x_edge_all, delta_x_all, delta_y_all, \\\n",
    "                x_full_all, x_edge_full_all, attention_all, seg_list = flow_out\n",
    "            last_flow =  F.interpolate(last_flow, scale_factor=2, mode='bilinear')\n",
    "\n",
    "        bz = pose.size(0)\n",
    "\n",
    "        left_last_flow = last_flow[0:bz]\n",
    "        torso_last_flow = last_flow[bz:2*bz]\n",
    "        right_last_flow = last_flow[2*bz:]\n",
    "\n",
    "        left_warped_full_cloth = F.grid_sample(clothes_left.cuda(), left_last_flow.permute(0, 2, 3, 1),mode='bilinear', padding_mode='zeros')\n",
    "        torso_warped_full_cloth = F.grid_sample(clothes_torso.cuda(), torso_last_flow.permute(0, 2, 3, 1),mode='bilinear', padding_mode='zeros')\n",
    "        right_warped_full_cloth = F.grid_sample(clothes_right.cuda(), right_last_flow.permute(0, 2, 3, 1),mode='bilinear', padding_mode='zeros')\n",
    "\n",
    "        left_warped_cloth_edge = F.grid_sample(left_cloth_sleeve_mask.cuda(), left_last_flow.permute(0, 2, 3, 1),mode='nearest', padding_mode='zeros')\n",
    "        torso_warped_cloth_edge = F.grid_sample(cloth_torso_mask.cuda(), torso_last_flow.permute(0, 2, 3, 1),mode='nearest', padding_mode='zeros')\n",
    "        right_warped_cloth_edge = F.grid_sample(right_cloth_sleeve_mask.cuda(), right_last_flow.permute(0, 2, 3, 1),mode='nearest', padding_mode='zeros')\n",
    "\n",
    "        for bb in range(bz):\n",
    "            seg_preds = torch.argmax(softmax(seg_list[-1]),dim=1)[:,None,...].float()\n",
    "            if opt.resolution == 1024:\n",
    "                seg_preds = F.interpolate(seg_preds, scale_factor=2, mode='nearest')\n",
    "\n",
    "            c_type = data['c_type'][bb]\n",
    "\n",
    "            if opt.dataset == 'vitonhd':\n",
    "                left_mask = (seg_preds[bb]==1).float()\n",
    "                torso_mask = (seg_preds[bb]==2).float()\n",
    "                right_mask = (seg_preds[bb]==3).float()\n",
    "\n",
    "                left_arm_mask = (seg_preds[bb]==4).float()\n",
    "                right_arm_mask = (seg_preds[bb]==5).float()\n",
    "                neck_mask = (seg_preds[bb]==6).float()\n",
    "\n",
    "                warped_cloth_fusion = left_warped_full_cloth[bb] * left_mask + \\\n",
    "                                    torso_warped_full_cloth[bb] * torso_mask + \\\n",
    "                                    right_warped_full_cloth[bb] * right_mask\n",
    "                \n",
    "                warped_edge_fusion = left_warped_cloth_edge[bb] * left_mask * 1 + \\\n",
    "                                        torso_warped_cloth_edge[bb] * torso_mask * 2 + \\\n",
    "                                        right_warped_cloth_edge[bb] * right_mask * 3\n",
    "\n",
    "                warped_cloth_fusion = warped_cloth_fusion * (1-preserve_mask3[bb])\n",
    "                warped_edge_fusion = warped_edge_fusion * (1-preserve_mask3[bb])\n",
    "                \n",
    "                warped_edge_fusion = warped_edge_fusion + \\\n",
    "                                        left_arm_mask * 4 + \\\n",
    "                                        right_arm_mask * 5 + \\\n",
    "                                        neck_mask * 6\n",
    "            elif opt.dataset == 'dresscode':\n",
    "                if c_type == 'upper' or c_type == 'dresses':\n",
    "                    left_mask = (seg_preds[bb]==1).float()\n",
    "                    torso_mask = (seg_preds[bb]==2).float()\n",
    "                    right_mask = (seg_preds[bb]==3).float()\n",
    "                else:\n",
    "                    left_mask = (seg_preds[bb]==4).float()\n",
    "                    torso_mask = (seg_preds[bb]==5).float()\n",
    "                    right_mask = (seg_preds[bb]==6).float()\n",
    "\n",
    "                left_arms_mask = (seg_preds[bb]==7).float()\n",
    "                right_arms_mask = (seg_preds[bb]==8).float()\n",
    "                neck_mask = (seg_preds[bb]==9).float()\n",
    "\n",
    "                warped_cloth_fusion = left_warped_full_cloth[bb] * left_mask + \\\n",
    "                                    torso_warped_full_cloth[bb] * torso_mask + \\\n",
    "                                    right_warped_full_cloth[bb] * right_mask\n",
    "\n",
    "                if c_type == 'upper' or c_type == 'dresses':\n",
    "                    warped_edge_fusion = left_warped_cloth_edge[bb] * left_mask * 1 + \\\n",
    "                                        torso_warped_cloth_edge[bb] * torso_mask * 2 + \\\n",
    "                                        right_warped_cloth_edge[bb] * right_mask * 3\n",
    "                else:\n",
    "                    warped_edge_fusion = left_warped_cloth_edge[bb] * left_mask * 4 + \\\n",
    "                                        torso_warped_cloth_edge[bb] * torso_mask * 5 + \\\n",
    "                                        right_warped_cloth_edge[bb] * right_mask * 6\n",
    "\n",
    "                warped_cloth_fusion = warped_cloth_fusion * (1-preserve_mask3[bb])\n",
    "                warped_edge_fusion = warped_edge_fusion * (1-preserve_mask3[bb])\n",
    "\n",
    "                warped_edge_fusion = warped_edge_fusion + \\\n",
    "                                        left_arms_mask * 7 + \\\n",
    "                                        right_arms_mask * 8 + \\\n",
    "                                        neck_mask * 9\n",
    "\n",
    "            eee = warped_cloth_fusion\n",
    "            eee_edge = torch.cat([warped_edge_fusion,warped_edge_fusion,warped_edge_fusion],0)\n",
    "            eee_edge = eee_edge.permute(1,2,0).detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            cv_img = (eee.permute(1, 2, 0).detach().cpu().numpy()+1)/2\n",
    "            rgb = (cv_img*255).astype(np.uint8)\n",
    "            bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            bgr = np.concatenate([bgr,eee_edge],1)\n",
    "\n",
    "            cloth_id = data['color_path'][bb].split('/')[-1]\n",
    "            person_id = data['img_path'][bb].split('/')[-1]\n",
    "            save_path = 'sample/'+opt.name+'/'+c_type+'___'+person_id+'___'+cloth_id[:-4]+'.png'\n",
    "            cv2.imwrite(save_path, bgr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
